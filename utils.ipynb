{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BrEaST -  usuwanie other i mask folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "source_dir = r\"dataset\\BrEaST\" \n",
    "target_dir = os.path.join(source_dir, \"masks\")\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith(\".png\") and \"_tumor\" in filename:\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        new_filename = filename.replace(\"_tumor\", \"\")\n",
    "        target_path = os.path.join(target_dir, new_filename)\n",
    "        shutil.move(source_path, target_path)\n",
    "\n",
    "    elif filename.endswith(\".png\") and \"_other\" in filename:\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        os.remove(source_path)\n",
    "\n",
    "print(\"Done! Moved And Deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "excel_path = r'dataset\\BrEaST\\BrEaST-Lesions-USG-clinical-data-Dec-15-2023.xlsx'\n",
    "masks_dir = r'dataset\\BrEaST\\masks'\n",
    "\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mask_filename = row[1] \n",
    "    label = str(row[20]).strip().lower()  \n",
    "\n",
    "    mask_path = os.path.join(masks_dir, mask_filename)\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Nie znaleziono: {mask_path}\")\n",
    "        continue\n",
    "\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask_array = np.array(mask)\n",
    "\n",
    "\n",
    "    color_mask = np.zeros((*mask_array.shape, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    if label == 'benign':\n",
    "        color_mask[mask_array == 255] = [0, 255, 0]  # zielony\n",
    "    elif label == 'malignant':\n",
    "        color_mask[mask_array == 255] = [255, 0, 0]  # czerwony\n",
    "\n",
    "\n",
    "    output_path = os.path.join(masks_dir, mask_filename)\n",
    "    Image.fromarray(color_mask).save(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUSBRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Renamed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "source_dir = r\"dataset\\BUSBRA\\masks\" \n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith(\".png\") and \"mask\" in filename:\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        new_filename = filename.replace(\"mask\", \"bus\")\n",
    "        output_path = os.path.join(source_dir, new_filename)\n",
    "        os.rename(source_path, output_path)\n",
    "print(\"Done! Renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "excel_path = r'dataset\\BUSBRA\\bus_data.csv'\n",
    "masks_dir = r'dataset\\BUSBRA\\masks'\n",
    "\n",
    "df = pd.read_csv(excel_path)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mask_filename = row.iloc[0]+\".png\"\n",
    "    label = str(row.iloc[3]).strip().lower()  \n",
    "\n",
    "    mask_path = os.path.join(masks_dir, mask_filename)\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Nie znaleziono: {mask_path}\")\n",
    "        continue\n",
    "\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask_array = np.array(mask)\n",
    "\n",
    "    color_mask = np.zeros((*mask_array.shape, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    if label == 'benign':\n",
    "        color_mask[mask_array == 255] = [0, 255, 0]  # zielony\n",
    "    elif label == 'malignant':\n",
    "        color_mask[mask_array == 255] = [255, 0, 0]  # czerwony\n",
    "\n",
    "\n",
    "    output_path = os.path.join(masks_dir, mask_filename)\n",
    "    Image.fromarray(color_mask).save(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Moved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = r\"dataset\\BUSI\\normal\" \n",
    "target_dir = os.path.join(source_dir, \"masks\")\n",
    "target_dir_1 = os.path.join(source_dir, \"images\")\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "os.makedirs(target_dir_1, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename in [\"masks\", \"images\"]:\n",
    "        continue\n",
    "    source_path = os.path.join(source_dir, filename)\n",
    "\n",
    "    if filename.endswith(\".png\") and \"_mask\" in filename:\n",
    "        new_filename = filename.replace(\"_mask\", \"\")\n",
    "        target_path = os.path.join(target_dir, new_filename)\n",
    "    else:\n",
    "        target_path = os.path.join(target_dir_1, filename)\n",
    "    shutil.move(source_path, target_path)\n",
    "\n",
    "print(\"Done! Moved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "source_dir = r'dataset\\BUSI\\benign\\masks'\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    mask_path = os.path.join(source_dir, filename)\n",
    "\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask_array = np.array(mask)\n",
    "    color_mask = np.zeros((*mask_array.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    # if label == 'benign':\n",
    "    color_mask[mask_array == 255] = [0, 255, 0]  # zielony\n",
    "    # elif label == 'malignant':\n",
    "    #color_mask[mask_array == 255] = [255, 0, 0]  # czerwony\n",
    "\n",
    "    output_path = os.path.join(source_dir, filename)\n",
    "    Image.fromarray(color_mask).save(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUS-UCLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = r\"dataset\\BrEaST\\masks\" \n",
    "output_path =r\"dataset\\BrEaST\"\n",
    "\n",
    "target_dir = os.path.join(output_path, \"benign\", \"masks\")\n",
    "target_dir_1 = os.path.join(output_path, \"malignant\", \"masks\")\n",
    "target_dir_2 = os.path.join(output_path, \"normal\", \"masks\")\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "os.makedirs(target_dir_1, exist_ok=True)\n",
    "os.makedirs(target_dir_2, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    image_path = os.path.join(source_dir, filename)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    flat_pixels = image_array.reshape(-1, 3)\n",
    "\n",
    "    if np.any(np.all(flat_pixels == [0, 255, 0], axis=1)):\n",
    "        new_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "    elif np.any(np.all(flat_pixels == [255, 0, 0], axis=1)):\n",
    "        new_path = os.path.join(target_dir_1, filename)\n",
    "        \n",
    "    else:\n",
    "        new_path = os.path.join(target_dir_2, filename)\n",
    "    \n",
    "    shutil.move(image_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = r\"dataset\\BrEaST\\images\"\n",
    "output_path = r\"dataset\\BrEaST\"\n",
    "\n",
    "target_dirs = {\n",
    "    \"benign\": os.path.join(output_path, \"benign\", \"images\"),\n",
    "    \"malignant\": os.path.join(output_path, \"malignant\", \"images\"),\n",
    "    \"normal\": os.path.join(output_path, \"normal\", \"images\"),\n",
    "}\n",
    "\n",
    "mask_dirs = {\n",
    "    \"benign\": os.path.join(output_path, \"benign\", \"masks\"),\n",
    "    \"malignant\": os.path.join(output_path, \"malignant\", \"masks\"),\n",
    "    \"normal\": os.path.join(output_path, \"normal\", \"masks\"),\n",
    "}\n",
    "\n",
    "for path in target_dirs.values():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "for label, mask_dir in mask_dirs.items():\n",
    "    for mask_filename in os.listdir(mask_dir):\n",
    "        image_path = os.path.join(source_dir, mask_filename)\n",
    "        if os.path.exists(image_path):\n",
    "            shutil.move(image_path, os.path.join(target_dirs[label], mask_filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzanie: BrEaST\n",
      "Przetwarzanie: BUS-UCLM\n",
      "Przetwarzanie: BUSBRA\n",
      "Przetwarzanie: BUSI\n",
      "Zrobione.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parametry\n",
    "SOURCE_DIR = \"dataset_1\"\n",
    "TARGET_DIR = \"dataset_split\"\n",
    "SPLIT_RATIOS = (0.7, 0.15, 0.15)  # train, val, test\n",
    "\n",
    "def get_image_mask_pairs(class_dir):\n",
    "    image_dir = os.path.join(class_dir, \"images\")\n",
    "    mask_dir = os.path.join(class_dir, \"masks\")\n",
    "    image_paths = sorted(glob(os.path.join(image_dir, \"*\")))\n",
    "    \n",
    "    # Zakładamy, że obrazy i maski mają taką samą nazwę\n",
    "    base_names = [os.path.basename(p) for p in image_paths]\n",
    "    image_mask_pairs = [(os.path.join(image_dir, name), os.path.join(mask_dir, name)) for name in base_names]\n",
    "    return image_mask_pairs\n",
    "\n",
    "def save_split(pairs, split_name, dataset_name):\n",
    "    for img_path, mask_path in pairs:\n",
    "        base_name = os.path.basename(img_path)\n",
    "        for typ, path in [(\"images\", img_path), (\"masks\", mask_path)]:\n",
    "            out_dir = os.path.join(TARGET_DIR, dataset_name, split_name, typ)\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            shutil.copy(path, os.path.join(out_dir, base_name))\n",
    "\n",
    "def stratified_split(dataset_name):\n",
    "    dataset_path = os.path.join(SOURCE_DIR, dataset_name)\n",
    "    all_pairs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        if \"images\" in os.listdir(class_dir):  # np. BUSI/normal/images/\n",
    "            pairs = get_image_mask_pairs(class_dir)\n",
    "        else:\n",
    "            continue  # pomijamy foldery bez obrazów\n",
    "\n",
    "        all_pairs.extend(pairs)\n",
    "        all_labels.extend([class_name] * len(pairs))\n",
    "    \n",
    "    # Split stratified\n",
    "    train_ratio, val_ratio, test_ratio = SPLIT_RATIOS\n",
    "    train_val_pairs, test_pairs, train_val_labels, test_labels = train_test_split(\n",
    "        all_pairs, all_labels, test_size=test_ratio, stratify=all_labels, random_state=42)\n",
    "\n",
    "    val_split = val_ratio / (train_ratio + val_ratio)\n",
    "    train_pairs, val_pairs, train_labels, val_labels = train_test_split(\n",
    "        train_val_pairs, train_val_labels, test_size=val_split, stratify=train_val_labels, random_state=42)\n",
    "    \n",
    "    # Zapisz\n",
    "    save_split(train_pairs, \"train\", dataset_name)\n",
    "    save_split(val_pairs, \"val\", dataset_name)\n",
    "    save_split(test_pairs, \"test\", dataset_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datasets = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
    "    for ds in datasets:\n",
    "        print(f\"Przetwarzanie: {ds}\")\n",
    "        stratified_split(ds)\n",
    "    print(\"Zrobione.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalanie zakończone. Nazwy plików zachowane.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "SOURCE_DIR = \"dataset_split\"\n",
    "FINAL_DIR = \"merged_dataset\"\n",
    "\n",
    "def merge_datasets():\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    # Utwórz foldery wyjściowe\n",
    "    for split in splits:\n",
    "        img_out_dir = os.path.join(FINAL_DIR, split, \"images\")\n",
    "        mask_out_dir = os.path.join(FINAL_DIR, split, \"masks\")\n",
    "        os.makedirs(img_out_dir, exist_ok=True)\n",
    "        os.makedirs(mask_out_dir, exist_ok=True)\n",
    "\n",
    "    for dataset_name in os.listdir(SOURCE_DIR):\n",
    "        dataset_path = os.path.join(SOURCE_DIR, dataset_name)\n",
    "        if not os.path.isdir(dataset_path):\n",
    "            continue\n",
    "\n",
    "        for split in splits:\n",
    "            img_in = os.path.join(dataset_path, split, \"images\")\n",
    "            mask_in = os.path.join(dataset_path, split, \"masks\")\n",
    "            if not os.path.exists(img_in):\n",
    "                continue\n",
    "\n",
    "            img_out = os.path.join(FINAL_DIR, split, \"images\")\n",
    "            mask_out = os.path.join(FINAL_DIR, split, \"masks\")\n",
    "\n",
    "            img_paths = sorted(glob(os.path.join(img_in, \"*\")))\n",
    "            for img_path in img_paths:\n",
    "                mask_path = os.path.join(mask_in, os.path.basename(img_path))\n",
    "                if not os.path.exists(mask_path):\n",
    "                    continue  # Pomijaj, jeśli brak maski\n",
    "\n",
    "                # Kopiuj z ORYGINALNĄ nazwą pliku\n",
    "                shutil.copy(img_path, os.path.join(img_out, os.path.basename(img_path)))\n",
    "                shutil.copy(mask_path, os.path.join(mask_out, os.path.basename(mask_path)))\n",
    "\n",
    "    print(\"Scalanie zakończone. Nazwy plików zachowane.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justy\\AppData\\Local\\Temp\\ipykernel_25028\\2241354511.py:24: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform (alpha=1, sigma=20, alpha_affine=5)\n",
      "Augmenting: 100%|██████████| 2509/2509 [01:38<00:00, 25.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano 1930 par obraz+mask.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "\n",
    "# Ścieżki\n",
    "IMAGE_DIR = \"merged_dataset/train/images\"\n",
    "MASK_DIR = \"merged_dataset/train/masks\"\n",
    "OUTPUT_IMG_DIR = \"augmented_dataset/images\"\n",
    "OUTPUT_MASK_DIR = \"augmented_dataset/masks\"\n",
    "os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_MASK_DIR, exist_ok=True)\n",
    "\n",
    "# Ile augmentacji na obraz\n",
    "AUG_PER_IMAGE = 5\n",
    "\n",
    "# Augmentacje\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.ElasticTransform (alpha=1, sigma=20, alpha_affine=5)\n",
    "])\n",
    "\n",
    "def is_black_mask(mask_path):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "    return np.max(mask) == 0\n",
    "\n",
    "def augment_normal_images():\n",
    "    img_paths = sorted(glob(os.path.join(IMAGE_DIR, \"*\")))\n",
    "\n",
    "    counter = 0\n",
    "    for img_path in tqdm(img_paths, desc=\"Augmenting\"):\n",
    "        fname = os.path.basename(img_path)\n",
    "        mask_path = os.path.join(MASK_DIR, fname)\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            continue\n",
    "        if not is_black_mask(mask_path):\n",
    "            continue  # pomijamy nienormalne\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "\n",
    "        for i in range(AUG_PER_IMAGE):\n",
    "            augmented = transform(image=image, mask=mask)\n",
    "            aug_img = augmented[\"image\"]\n",
    "            aug_mask = augmented[\"mask\"]\n",
    "\n",
    "            new_name = f\"aug_{counter:05d}.png\"\n",
    "            cv2.imwrite(os.path.join(OUTPUT_IMG_DIR, new_name), aug_img)\n",
    "            cv2.imwrite(os.path.join(OUTPUT_MASK_DIR, new_name), aug_mask)\n",
    "            counter += 1\n",
    "\n",
    "    print(f\"Zapisano {counter} par obraz+mask.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    augment_normal_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obrazy: merged_dataset/train/images:   0%|          | 0/2509 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Obrazy: merged_dataset/train/images: 100%|██████████| 2509/2509 [00:42<00:00, 59.55it/s]\n",
      "Obrazy: merged_dataset/val/images: 100%|██████████| 541/541 [00:09<00:00, 54.85it/s]\n",
      "Obrazy: merged_dataset/test/images: 100%|██████████| 540/540 [00:10<00:00, 51.88it/s]\n",
      "Obrazy: augmented_dataset/images: 100%|██████████| 1930/1930 [00:56<00:00, 34.08it/s]\n",
      "Maski: merged_dataset/train/masks: 100%|██████████| 2509/2509 [00:10<00:00, 233.35it/s]\n",
      "Maski: merged_dataset/val/masks: 100%|██████████| 541/541 [00:06<00:00, 82.32it/s] \n",
      "Maski: merged_dataset/test/masks: 100%|██████████| 540/540 [00:06<00:00, 83.77it/s] \n",
      "Maski: augmented_dataset/masks: 100%|██████████| 1930/1930 [00:17<00:00, 109.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ścieżki do folderów (osobno obrazy i maski dla jasności)\n",
    "IMAGE_DIRS = [\n",
    "    \"merged_dataset/train/images\",\n",
    "    \"merged_dataset/val/images\",\n",
    "    \"merged_dataset/test/images\",\n",
    "    \"augmented_dataset/images\"\n",
    "]\n",
    "\n",
    "MASK_DIRS = [\n",
    "    \"merged_dataset/train/masks\",\n",
    "    \"merged_dataset/val/masks\",\n",
    "    \"merged_dataset/test/masks\",\n",
    "    \"augmented_dataset/masks\"\n",
    "]\n",
    "\n",
    "OUTPUT_ROOT = \"final_dataset\"\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def process_image(path):\n",
    "    \"\"\"Normalizacja obrazu do z-score i konwersja na float32.\"\"\"\n",
    "    gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    mean, std = gray.mean(), gray.std()\n",
    "    std = std if std > 0 else 1.0\n",
    "    return (gray - mean) / std\n",
    "\n",
    "def save_as_uint8(img, output_path):\n",
    "    \"\"\"Skalowanie do [0, 255] tylko do wizualizacji (opcjonalne).\"\"\"\n",
    "    if img.max() > img.min():\n",
    "        img_uint8 = np.clip((img - img.min()) / (img.max() - img.min()) * 255, 0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_uint8 = img.astype(np.uint8)\n",
    "    cv2.imwrite(output_path, img_uint8)\n",
    "\n",
    "def normalize_and_save_all():\n",
    "    # Obrazy\n",
    "    for img_dir in IMAGE_DIRS:\n",
    "        output_dir = os.path.join(OUTPUT_ROOT, os.path.relpath(img_dir, \".\"))\n",
    "        ensure_dir(output_dir)\n",
    "        for path in tqdm(glob(os.path.join(img_dir, \"*\")), desc=f\"Obrazy: {img_dir}\"):\n",
    "            img = process_image(path)\n",
    "            save_as_uint8(img, os.path.join(output_dir, os.path.basename(path)))\n",
    "\n",
    "    # Maski\n",
    "    for mask_dir in MASK_DIRS:\n",
    "        output_dir = os.path.join(OUTPUT_ROOT, os.path.relpath(mask_dir, \".\"))\n",
    "        ensure_dir(output_dir)\n",
    "        for path in tqdm(glob(os.path.join(mask_dir, \"*\")), desc=f\"Maski: {mask_dir}\"):\n",
    "            mask = cv2.imread(path)\n",
    "            cv2.imwrite(os.path.join(output_dir, os.path.basename(path)), mask)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_and_save_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "mask_path = r\"grayscale_zscore_dataset\\final_dataset\\train\\masks\\malignant (55).png\"\n",
    "mask = np.array(Image.open(mask_path))  # <- KLUCZOWE\n",
    "print(np.unique(mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(r'final_dataset\\test\\images\\ALWI_002.png')\n",
    "print(img.mode) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
